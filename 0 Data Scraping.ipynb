{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping\n",
    "\n",
    "## Twitter Data\n",
    "\n",
    "Here I scrape tweets from @nytimes made between 2022-01-01 and mid-April 2022 using the Twitter API, twint, and snscrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Getting tweets from @nytimes using the Twitter API v2.\n",
    "    Unfortunately, I was only able to get 30 days of tweets using this method.\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "twitterAPI = 'https://api.twitter.com/2/users/'\n",
    "nytUserID = '807095' # Twitter ID for the New York Times\n",
    "startTime = '2022-01-01T00:00:00.000Z' # Beginning of the year\n",
    "endTime = '2022-04-30T00:00:00.000Z' # End of April\n",
    "\n",
    "resultingJSON = {'meta': {'next_token': ''}}\n",
    "while True:\n",
    "    try:\n",
    "        pagination_token = resultingJSON['meta']['next_token']\n",
    "        if pagination_token != '':\n",
    "            pagination_token = 'pagination_token=' + pagination_token\n",
    "    except KeyError:\n",
    "        break\n",
    "    fields = ('/tweets?max_results=100&' +\n",
    "                pagination_token +\n",
    "                '&start_time=' + startTime +\n",
    "                '&end_time=' + endTime +\n",
    "                '&tweet.fields=id,created_at,text,author_id,in_reply_to_user_id,referenced_tweets,attachments,geo,entities,public_metrics,source,context_annotations,conversation_id&media.fields=media_key,duration_ms,height,preview_image_url,type,url,width,public_metrics,alt_text'\n",
    "    )\n",
    "    URL = twitterAPI + nytUserID + fields\n",
    "\n",
    "    req = requests.get(URL, headers = {'Authorization': f'Bearer {os.environ[\"BEARER_TOKEN\"]}'})\n",
    "    resultingJSON = req.json()\n",
    "    \n",
    "    with open('nyt_' + pagination_token + '.json', 'w') as file:\n",
    "        json.dump(resultingJSON, file)\n",
    "\n",
    "    time.sleep(10) # To keep the number of requests well below the Twitter rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Getting tweets from @nytimes using twint.\n",
    "    Unfortunately, I was only able to get 10 days of tweets using this method.  Moreover, retweets are missing.\n",
    "'''\n",
    "\n",
    "import twint\n",
    "config = twint.Config()\n",
    "config.Username = 'nytimes'\n",
    "config.Since = '2022-01-01'\n",
    "config.Store_json = True\n",
    "config.Output = 'nyt_data_twint.json'\n",
    "config.Retweets = True\n",
    "\n",
    "twint.run.Search(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Getting tweets from @nytimes using snscrape, on command line.\n",
    "    This method seems to be able to get tweets from Jan 2022, unlike the Twitter API and twint.  However, retweets are missing.\n",
    "'''\n",
    "\n",
    "# snscrape --jsonl --progress --since 2022-01-01 twitter-search \"from:nytimes until:2022-04-30\" >> nyt_twitter_data.json"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
